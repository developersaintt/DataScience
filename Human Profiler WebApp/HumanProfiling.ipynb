{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### If you want to replicate the project below the dependency list.\r\n",
        "\r\n",
        "\r\n",
        "| Library         | Version      |\r\n",
        "| --------------- |-------------:|\r\n",
        "| tensorflow      | 2.3.0        |\r\n",
        "| keras           | 2.4.3        |\r\n",
        "| MTCNN           | 0.1.0        |"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import anvil.media\r\n",
        "import anvil.server\r\n",
        "from mtcnn import MTCNN\r\n",
        "\r\n",
        "detector = MTCNN()\r\n",
        "\r\n",
        "img_size = 64\r\n",
        "\r\n",
        "model = tf.keras.models.load_model(\"yu4u-age-gender.model\")\r\n",
        "\r\n",
        "anvil.server.connect('3HZIYGCZ64G5GHMHXHBUYJKY-QE53PUIDL6P654KY')\r\n",
        "\r\n",
        "@anvil.server.callable\r\n",
        "def profile_image(file):\r\n",
        "  with anvil.media.TempFile(file) as filename:\r\n",
        "    img = cv2.imread(filename)\r\n",
        "  input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "  img_h, img_w, _ = np.shape(input_img)\r\n",
        "\r\n",
        "  faces = detector.detect_faces(img)\r\n",
        "\r\n",
        "  all_labels = [];\r\n",
        "\r\n",
        "  margin = 0.2\r\n",
        "  for face in faces:\r\n",
        "      bounding_box = face['box']\r\n",
        "      if face['confidence']>.90: \r\n",
        "          x1, y1, x2, y2, w, h =  bounding_box[0], bounding_box[1],bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3],bounding_box[2],bounding_box[3]\r\n",
        "          xw1 = max(int(x1 - margin * w), 0)\r\n",
        "          yw1 = max(int(y1 - margin * h), 0)\r\n",
        "          xw2 = min(int(x2 + margin * w), img_w - 1)\r\n",
        "          yw2 = min(int(y2 + margin * h), img_h - 1)\r\n",
        "\r\n",
        "          face_boundary = cv2.resize(img[yw1:yw2+1, xw1:xw2+1],(img_size,img_size)).reshape(-1,64,64,3)\r\n",
        "\r\n",
        "          # predict ages and genders of the detected faces\r\n",
        "          results = model.predict(face_boundary)\r\n",
        "          predicted_genders = results[0]\r\n",
        "          ages = np.arange(0, 101).reshape(101, 1)\r\n",
        "          predicted_ages = results[1].dot(ages).flatten()\r\n",
        "\r\n",
        "          pred_gender = \"Male\" if predicted_genders[0][0] < 0.5 else \"Female\"\r\n",
        "          label_str = \"{} of {} years\".format(pred_gender,int(predicted_ages[0]))\r\n",
        "          all_labels.append(label_str)\r\n",
        "          \r\n",
        "  return all_labels"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment (dev)\" as SERVER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - 6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66e97d77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING - 6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66e97d77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING - 7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f66e97d77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1607181209233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}